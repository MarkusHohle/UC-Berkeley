{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7c76c51-8abb-4b01-b747-078e094301d3",
   "metadata": {},
   "source": [
    "## Bigram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7fc378-17c3-4b9f-8a7e-5a7152645871",
   "metadata": {},
   "source": [
    "As an example of a simple language model, we want to generate names using the bigram method. The idea is that we:<br>\n",
    "<br>\n",
    "1) download a dataset containing many different names<br>\n",
    "2) derive the relative frequency of each letter followed by another specific letter in these names and plot a matrix of these frequencies.<br>\n",
    "3) generate new names, based on these frequencies and compare the result to a completely random model<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c316d4-4ef8-4b57-b222-af8056111a31",
   "metadata": {},
   "source": [
    "First, we call the required libraries..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cf709d-b438-42e9-9478-626c9919a259",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import urllib.request\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625c7a8f-6f90-442a-b621-c2ddf2cb94ca",
   "metadata": {},
   "source": [
    "and download the dataset $names$ from the GitHub repository of [Andrej Karpathy](https://en.wikipedia.org/wiki/Andrej_Karpathy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fd2859-5db2-4b93-9c61-3bd19bffb89a",
   "metadata": {},
   "source": [
    "We are ready for the creating the model now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c152729-1f4b-4d3f-9aa9-5214df162f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiGramModel():\n",
    "    \n",
    "    #retrieving data\n",
    "    def __init__(self, *dataset: str):\n",
    "\n",
    "        if dataset:\n",
    "            for dataset in dataset:\n",
    "                names = open(dataset, 'r').read().splitlines()\n",
    "\n",
    "        else:\n",
    "            my_url = 'https://raw.githubusercontent.com/karpathy/makemore/master/names.txt'\n",
    "\n",
    "            with urllib.request.urlopen(my_url) as f:\n",
    "                names_text = f.read().decode('utf-8')\n",
    "            names = names_text.split()\n",
    "        \n",
    "        self.names = names\n",
    "        \n",
    "        \n",
    "    def CreateBiGramMatrix(self):\n",
    "        \n",
    "        #1) creating an alphabet of all token\n",
    "        chars = sorted(list(set(''.join(self.names))))\n",
    "        chars += ['<S>'] + ['<E>'] #adding end and start token\n",
    "        SizeA = len(chars)         #size of the alphabet = number of token\n",
    "        print(str(SizeA) + ' different token')\n",
    "\n",
    "        #2) creating dictionary from string to numbers and vice versa\n",
    "        stoi = { ch: i  for i, ch in enumerate(chars)}\n",
    "        itos = { i : ch for i, ch in enumerate(chars)}\n",
    "        \n",
    "        #3) creating matrix for frequencies\n",
    "        N = np.zeros((SizeA, SizeA))\n",
    "\n",
    "        for n in self.names:\n",
    "            nL = ['<S>'] + list(n) + ['<E>']\n",
    "            for char1, char2 in zip(nL, nL[1:]):\n",
    "                idx1 = stoi[char1]\n",
    "                idx2 = stoi[char2]\n",
    "                N[idx1,idx2] += 1\n",
    "\n",
    "        #frequencies --> probabilities\n",
    "        Nsam = N/np.sum(N+0.0001, axis = 1, keepdims = True)\n",
    "                \n",
    "\n",
    "        #plotting N##########################################################\n",
    "        Ndf   = pd.DataFrame(Nsam*100, columns = chars)\n",
    "\n",
    "        plt.figure(figsize = (len(chars)/2,len(chars)/2))\n",
    "        sns.heatmap(Ndf, cmap = 'Blues', annot = False, yticklabels = chars,\\\n",
    "                    cbar_kws={'label': 'rel frequency [%]'})\n",
    "        plt.savefig('bigram_names.pdf')\n",
    "        #####################################################################\n",
    "        \n",
    "        self.Nsam = Nsam\n",
    "        self.itos = itos\n",
    "        \n",
    "        \n",
    "    def SampleNames(self, Nnames = 10, NotRandom = True):\n",
    "        \n",
    "        itos  = self.itos\n",
    "        Nsam  = self.Nsam\n",
    "        Nchar = N.shape[0]\n",
    "\n",
    "        #generating ten names based on N or randomly\n",
    "        for i in range(Nnames):\n",
    "            \n",
    "            out = []\n",
    "            idx = Nchar-2#starting with the start symbol       \n",
    "            \n",
    "            while True:\n",
    "                if NotRandom:\n",
    "                    p   = Nsam[idx,:]\n",
    "                    # drawing token randomly, based on Nsam, returns 1 or zeror\n",
    "                    idx = np.argmax(np.random.multinomial(1,p))\n",
    "                    \n",
    "                else:\n",
    "                    #random model as comparison\n",
    "                    idx = np.random.randint(0, Nchar)#upper value is EXCLUSIVE               \n",
    "              \n",
    "                if idx == Nchar-1: #end symbol\n",
    "                    break\n",
    "                \n",
    "                out.append(itos[idx])\n",
    "            \n",
    "            print(''.join(out))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb8008c-817e-4275-a756-e835024c241f",
   "metadata": {},
   "source": [
    "We run the __init__ in order to recive the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c27818-d7e1-41bc-9cf6-97abc634f864",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = BiGramModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2ee0aa-ae53-4f0f-a53c-af0fa880536b",
   "metadata": {},
   "source": [
    "Checking the first ten names in the corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed0be72-51b4-445c-898b-6c5516ab1f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(B.names[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4dacd7-61ac-4751-9359-11396a95ab41",
   "metadata": {},
   "source": [
    "Creating the frequency matrix and plotting it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dbd1b0-1014-41c2-9795-26f8de529956",
   "metadata": {},
   "outputs": [],
   "source": [
    "B.CreateBiGramMatrix() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb5a43a-742a-4c68-89ab-af29540bb629",
   "metadata": {},
   "source": [
    "We can see, that many combinations are more frequent than other combinations. Therefore, we can predict a token based on the previous one to some degree. In order to measure the amount of information we gained, we can calculate the entropy of the bigram matrix and compare it to a random sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dba22ff-f590-4711-a0c0-ff99227a9c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ntoken = len(B.Nsam[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad49441-13ad-4345-91d5-c01799f96891",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_rand = (Ntoken**2)*np.log(Ntoken)/Ntoken\n",
    "print(S_rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2bcf4e-b30a-49b4-a20b-7f3e77981ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = B.Nsam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6766f8-fbd8-4607-b80f-81b36e03579a",
   "metadata": {},
   "outputs": [],
   "source": [
    "S_bi = 0\n",
    "for i in range(Ntoken):\n",
    "    S_bi += np.sum(-N[:,i]*np.log(N[:,i]+1e-16))\n",
    "print(S_bi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bfeed3-1ab5-41aa-8d9c-9921ac1eaa7a",
   "metadata": {},
   "source": [
    "We gained a bit less than a factor of two, which is pretty common for Germanic languages.<br>\n",
    "Let us now generate names randomly. First, based on our model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42261720-af35-4246-9a71-f84281ff5b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nnames = 15\n",
    "B.SampleNames(Nnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1f9881-4e42-4f5a-ad57-5ec099d1e32c",
   "metadata": {},
   "source": [
    "...and now compared to a random sampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05618dae-bd3e-4490-8c02-3604649488f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "B.SampleNames(Nnames, NotRandom=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbd8939-da4f-46e1-9718-946128677984",
   "metadata": {},
   "source": [
    "Eventhough our model is pretty simple, we can clearly see a significant improvement!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
