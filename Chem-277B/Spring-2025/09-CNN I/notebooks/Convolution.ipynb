{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aafc06e9-e354-4534-b8b7-cbb2b24c0096",
   "metadata": {},
   "source": [
    "## Convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2e32d0-090c-4055-af3f-21bf35eba7a3",
   "metadata": {},
   "source": [
    "In this example, we want to explore convolution itself and the effect of different convolution kernel have on an image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e73d9ac-ae6e-4580-ba60-b6987ded86e2",
   "metadata": {},
   "source": [
    "**0) Loading and Preparing Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0f7e48-47fd-4b33-8e55-467fbdaeb8ab",
   "metadata": {},
   "source": [
    "Importing libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2375136-822f-464d-9cec-94b072310497",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25113b3-5738-4fa9-a876-66100c534c41",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5729ea-c3f8-470a-8763-04acc0fb881d",
   "metadata": {},
   "source": [
    "**1) Images in Python**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1d5347-1d68-4d09-901a-e0bba129a4b9",
   "metadata": {},
   "source": [
    "First, we want to explore images in Python:<br>\n",
    "Images are N-dimensional matrices, i.e. numpy arrays in python. Depending on the color scaling and the \"depth\" of the colors, the values might range from zero to one (if normalized), could be logical (zero *or* one, i.e. a black/white image) or often the values are integers ranging from zero to, say 255, if 8bit encoded.<br>\n",
    "Let us read an image and explore shape, values and type:<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22523517-ea4d-49de-934d-115c4e11fbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "I = plt.imread('2.jpg')\n",
    "print(type(I))          #np.array\n",
    "print(I.shape)          #RGB color image\n",
    "print(np.max(I))        #8 bit "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c43a5bd-af9d-4c4b-874f-e5ca879d14f7",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a13b41-ae4b-4d49-a8fa-f47a9a5034f1",
   "metadata": {},
   "source": [
    "We can display the image using *imshow*:<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58cf14b-fdf5-46e3-bd10-4a31aa9e8f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(I)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88164a5e-b824-477d-975f-00dda7c7ef64",
   "metadata": {},
   "source": [
    "The different color channels contain different information:<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7226231e-f733-410e-817a-8b179bc48127",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['red', 'green', 'blue']\n",
    "\n",
    "for i, c in zip(range(3), col):\n",
    "    plt.imshow(I[:,:,i], cmap = 'gray')\n",
    "    plt.title(c)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a504e415-4c41-4211-aaec-5f6f5b339cb1",
   "metadata": {},
   "source": [
    "We can see for example, that the leash is almost invisble in the blue color channel, but very bright in the red color channel.<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b31be37-2562-4c41-a42f-61e847596224",
   "metadata": {},
   "source": [
    "**2) Convolution**<br>\n",
    "<br>\n",
    "We first define a few common convolution filter/kernel and apply them to the image.<br>\n",
    "The filters have different purpose: they can sharpen edges, blur the background or enhance the foreground.<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a583332d-97af-4605-9cd7-3d7c60c045c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "K1  = np.array([[0, 0, 0], [0, 1, 0], [0, 0, 0]])\n",
    "#edges\n",
    "K2  = np.array([[1, 0, -1], [0, 0, 0], [-1, 0, 1]])\n",
    "K3  = np.array([[0, 1, 0], [1, -4, 1], [0, 1, 0]])\n",
    "K4  = np.array([[-1, -1, -1], [-1, 8, -1], [-1, -1, -1]])\n",
    "#sharpen\n",
    "K5  = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])\n",
    "#blur\n",
    "K6  = np.array([[1, 1, 1], [1, 1, 1], [1, 1, 1]])\n",
    "K6  = K6/9\n",
    "K7  = np.array([[1, 2, 1], [2, 4, 2], [1, 2, 1]])\n",
    "\n",
    "K8  = np.array([[-2, -1, 0], [-1, 1, 1], [0, 1, 2]])\n",
    "#misc\n",
    "K9  = np.array([[1, 0, 1], [0, 1, 0], [1, 0, 1]])\n",
    "K10 = np.array([[1, 1, 1], [0, 0, 0], [1, 1, 1]])\n",
    "K11 = np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]])\n",
    "K12 = np.array([[0, 0, 1], [0, 1, 0], [1, 0, 0]])\n",
    "K13 = np.array([[1, 0, 1], [1, 0, 1], [1, 0, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7eeaa7-a357-4eb8-94d3-a3b3ec2b0a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "Kall = np.dstack((K1,K2,K3,K4,K5,K6,K7,K8,K9,K10,K11,K12,K13))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435f4488-0813-42b9-a20a-e1a8b8ee4c9e",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feedea80-1f75-4099-9ee4-60f3ce3623dd",
   "metadata": {},
   "source": [
    "We like to visualize the filter first, before we are going to apply them to the image.<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89418464-cc0e-4263-ac19-deb7e6b7f842",
   "metadata": {},
   "outputs": [],
   "source": [
    "NK  = Kall.shape[2]\n",
    "PS  = int(np.ceil(NK**0.5))\n",
    "    \n",
    "plt.figure(figsize = (15,12))\n",
    "plt.subplots_adjust(hspace = 0.5)\n",
    "        \n",
    "for k in range(NK):\n",
    "    plt.subplot(PS,PS,k+1)\n",
    "    plt.imshow(Kall[:,:,k], cmap = 'gray')\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1f4c3d-ca8b-4a81-9c94-1976b49fad6b",
   "metadata": {},
   "source": [
    "Second, we define a simple convolution function. Note, that python has an internal convolution routine. The idea of the following function is to illustrate how convolution actually works:<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a526a2-5985-4794-b640-24aa98363a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MyConv(Image, K, padding = 0, stride = 1):\n",
    "    \n",
    "    #shape of input image\n",
    "    [xImgShape , yImgShape, numChan] = Image.shape\n",
    "    \n",
    "    [xK, yK] = K.shape\n",
    "    \n",
    "    xOutput = int((xImgShape - xK + 2*padding)/stride + 1)\n",
    "    yOutput = int((yImgShape - yK + 2*padding)/stride + 1)\n",
    "    \n",
    "    output  = np.zeros((xOutput, yOutput, numChan))\n",
    "    \n",
    "    imagePadded = np.zeros((xImgShape + 2*padding, yImgShape + 2*padding,\\\n",
    "                            numChan))\n",
    "    imagePadded[int(padding):int(padding + xImgShape),\\\n",
    "                int(padding):int(padding + yImgShape),:] = Image\n",
    "    \n",
    "    \n",
    "    for c in range(numChan):\n",
    "        for y in range(yOutput):\n",
    "            for x in range(xOutput):\n",
    "                \n",
    "                #finding corners of current slice\n",
    "                y_start = y*stride\n",
    "                y_end   = y_start + yK\n",
    "                x_start = x*stride\n",
    "                x_end   = x_start + xK\n",
    "                \n",
    "                current_slice = imagePadded[x_start:x_end, y_start:y_end, c]\n",
    "                s             = np.multiply(current_slice, K)\n",
    "                output[x,y,c] = np.sum(s)\n",
    "        \n",
    "    plt.imshow(output.sum(2), cmap = 'gray')\n",
    "    plt.title('after convolution with padding'\\\n",
    "                 ' = ' + str(padding) + ' and stride = ' + str(stride))\n",
    "    plt.show()\n",
    "      \n",
    "    return(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09aea91-c3a1-42e5-aebd-639bf7495f76",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a5d908-3c5a-44c8-89eb-14b4e9ee11a3",
   "metadata": {},
   "source": [
    "Let us experiment with different kernel, padding and stride length (see lecture).<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2c5ea0-af12-4c15-8a62-4452d6950a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ImageConv = MyConv(I, Kall[:,:,3],padding = 2, stride = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab9a2ae-42c8-429d-979d-ca65948d00f7",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110f5a77-dd22-47f1-b78d-772d925706a3",
   "metadata": {},
   "source": [
    "We note that for this particular filter, the background is enchanced, whereas the foreground is blurred. That might be helpful in order to separate the background from the foreground. <br>\n",
    "<br>\n",
    "Run *MyConv* for different padding and stride length and see how the equation<br>\n",
    "<br>\n",
    "$N_{out} = \\frac{\\left( N_{in}\\,-\\,N_{filt}\\,+\\,2\\,P \\right)}{S}$ + 1<br>\n",
    "<br>\n",
    "applies. Here, $N_{out}$ is the number of pixel of the output (convolved) image, $N_{in}$ the number of pixel of the input image, $N_{filt}$ the number of pixel of the convolution kernel and $P$ and $S$ refer to padding and stride length, respectively.<br>\n",
    "Now let us run the different kernel on all color channels using the convolution method from scipy:<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4e2fa6-be23-49df-a576-56c10de15527",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import convolve as Conv\n",
    "\n",
    "def MyConvAll(Image, Kall):\n",
    "\n",
    "    NK  = Kall.shape[2]\n",
    "    NC  = Image.shape[2]\n",
    "    \n",
    "    PS  = int(np.ceil(NK**0.5))\n",
    "    \n",
    "    for i in range(NC):\n",
    "        \n",
    "        plt.figure(figsize = (15,12))\n",
    "        plt.suptitle(\"after convolution of channel \" + str(i+1),\\\n",
    "                     fontsize = 20, y = 0.95)\n",
    "        plt.subplots_adjust(hspace = 0.5)\n",
    "        \n",
    "        for k in range(NK):\n",
    "        \n",
    "            plt.subplot(PS,PS,k+1)\n",
    "            Out = Conv(Image[:,:,i],Kall[:,:,k])\n",
    "            plt.imshow(Out, cmap = 'gray')\n",
    "        \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cb5cb2-6b3f-43f4-a68a-acb42b5543a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "MyConvAll(I, Kall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44072094-ea7c-4f81-9ce4-3a3c6d0d36c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
