{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2745e5af-b240-496c-9381-32dd93043514",
   "metadata": {},
   "source": [
    "## Example Logistic Model in Python<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf62522-67b1-4f4e-9835-779aa0d1e10d",
   "metadata": {},
   "source": [
    "As discussed in the lecture, we use logistic regression for classification. The term *\"logistic\"* refers to the logistic sigmoid equation. Typically, we work with a dichotomic model, meaning there are only two classes. Note, that *sklearn* also handles multi class problems.<br>\n",
    "The idea is that we start with a linear model for the log odds ratios of the probabilities $p$ for class $A$ and $1-p$ for class $B$ in the case of a two-class problem.<br>\n",
    "<br>\n",
    "$log\\left(\\frac{p}{1-p}\\right) = \\beta_0 + \\Sigma_{n = 1}^{N} \\beta_n\\,x_n + \\epsilon$\n",
    "<br>\n",
    "<br>\n",
    "Leading to the logistic equation<br>\n",
    "<br>\n",
    "$p = \\frac{e^{\\beta_0 + \\Sigma_{n = 1}^{N} \\beta_n\\,x_n + \\epsilon}}{1+e^{\\beta_0 + \\Sigma_{n = 1}^{N} \\beta_n\\,x_n + \\epsilon}}$\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac26dd3-0429-4675-ba49-b44dcd077250",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b422d41e-5312-4651-b910-9f4ad22b8709",
   "metadata": {},
   "source": [
    "**0) Loading Libraries**<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451b82bd-51a3-4175-b217-d0ddf1eedd2e",
   "metadata": {},
   "source": [
    "As usual, we load all the standard libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb9012e-0782-4119-ba06-50f4bb40c788",
   "metadata": {},
   "outputs": [],
   "source": [
    "#standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44fda6c2-f2c9-424f-b494-49fca40e7ddb",
   "metadata": {},
   "source": [
    "In contrast to a regression problem, we need to evaluate your classification model via accuracy in terms of how often it voted for the correct class and how sure it was about its decission (probabilities). For that purpose we want to create a confusion matrix and a so-called cross-entropy plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2909fd9b-4a99-4d9a-8c8c-f817fd8cabbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a161da9-a43b-4202-bf35-da913bc63cb8",
   "metadata": {},
   "source": [
    "The actual logistic regression is done by the tool **sm (stats model)**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a52c40-67e2-47df-a556-4f424c872faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f545b151-ba22-4407-aa54-17a7d355bbb7",
   "metadata": {},
   "source": [
    "Of course we need to normalize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14b4e8c-211e-427a-a5aa-927159e1a9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for scaling and normalizing the data\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62915558-df90-4208-95b9-bf277dc5f67d",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b90b84a-cf02-488a-8149-c7f147be5d66",
   "metadata": {},
   "source": [
    "**1) Loading and Extracting the Data**<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b086a72-fe3e-405b-9a37-2cc9af377cdb",
   "metadata": {},
   "source": [
    "This time we need to load the version of the molecule data set that is categorical (*\"Toxic\"* vs *\"Non-Toxic\"*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ae3277-b760-4041-a7e5-2913a72edbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train  = pd.read_csv(\"../04 Datasets/molecular_train_gbc_cat.csv\")\n",
    "Test   = pd.read_csv(\"../04 Datasets/molecular_test_gbc_cat.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d184d569-1a34-4b70-9fdd-a4050727751f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85151f60-20ac-49b0-bdf5-addccf29241c",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40cb66c6-5da0-4add-bad7-41c42e757302",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2263219c-a7a2-41c6-8f76-4a3558afb741",
   "metadata": {},
   "source": [
    "**2) Scaling the Data**<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d4799e-1a9a-4ee7-b11c-8bcdca0a8823",
   "metadata": {},
   "source": [
    "As before, we scale the data, but extract *X* and *Y* first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb010307-b2fa-41e2-b9da-1d5b86b3743a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range = (0, 1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f764b288-7c17-4c32-8145-d990d9149dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrain = Train.drop(['logP', 'label'], axis = 1)\n",
    "XTest  = Test.drop(['logP', 'label'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcae045-d9dd-4826-ac7f-889c3fd14717",
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainS = scaler.fit_transform(XTrain)\n",
    "TestS  = scaler.transform(XTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f72bc02-b604-429e-8562-a1c217325a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling returns an array, but we need a dataframe for the fit routine\n",
    "TrainS = pd.DataFrame(TrainS, columns = XTrain.columns)\n",
    "TestS  = pd.DataFrame(TestS, columns = XTest.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8cbac2-0178-485a-926e-d590b6787481",
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainS.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11b47b7-0eb1-45a7-9718-6f1f34fb5ba2",
   "metadata": {},
   "source": [
    "Extracting Y:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434fc597-b675-4009-9a20-85bc9d0e87be",
   "metadata": {},
   "outputs": [],
   "source": [
    "YTrain = Train[['label']]\n",
    "YTest  = Test[['label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274fb8ad-8d24-43fa-88f0-9d6cb37e41a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "YTrain.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2eb0b4-5918-4845-9e8a-eb5a47948add",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741767d1-ea74-4f65-8e02-935c20598ad3",
   "metadata": {},
   "source": [
    "**3) Performing the Fit**<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14147c5b-0ad3-497e-8697-a65d20ca7df5",
   "metadata": {},
   "source": [
    "For *sm* we need to add the intercept as a constant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11ea570-07fc-40ed-b037-0e2ca2e87f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sm.add_constant(TrainS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79c72e9-5397-4cde-96ec-92f6755775da",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30189968-550d-439e-bd17-d7a24b5c9cc3",
   "metadata": {},
   "source": [
    "And finally, for *sm* to understand that we have two classes, we generate so called dummy variables (see feature encoding)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f40032f-3fb2-461a-9fe0-575aee3dac93",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = pd.get_dummies(YTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694da6b1-e545-448f-b9c2-5f8aa23e39fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a776af44-67c4-4a79-90d1-aebf0f388f5e",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834fb74d-7d97-48be-9ece-242ecdabd244",
   "metadata": {},
   "source": [
    "Now we can run the fit. Note, that we have a binomial problem: *\"Toxic\"* or *\"Non-Toxic\"* and therefore set that as an input for *sm*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e6ec3a-9715-4c5b-977e-3adc2127430d",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = sm.GLM(Y, X, family = sm.families.Binomial()).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b155c4-1553-4daf-a9fb-86638d491c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571d600f-709a-4197-96ee-26375d5cc172",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de87da8-fcec-4179-894a-d83460ccb833",
   "metadata": {},
   "source": [
    "**4) Evaluating the Fit**<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00798634-d577-4a5c-b781-f78248e0ef8a",
   "metadata": {},
   "source": [
    "The results are comparable to those from the linear regression example, since we used the same data set.<br>\n",
    "Next, we want to evaluate the model and predict the labels from the test set and compare the predicted labels to the actual, true labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e97388-e92e-4320-b957-cd372c746ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predProbs   = my_model.predict(sm.add_constant(TestS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891a7415-eeac-47b5-9b3f-03be165825eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pred        = np.round(predProbs).astype(int) \n",
    "predictions = ['Non-Toxic' if i==1 else 'Toxic' for i in Pred] # we saw in my_model.summary() that the first label (index 0) referres to \"Non-Toxic\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222d3ed6-820a-46de-bd5d-0b9dcdd6bc97",
   "metadata": {},
   "source": [
    "Now we have the labels and the probabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a907b7-d0ce-4377-a9db-ad5d6bbe6717",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predProbs[:10]) #probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de3722c-581e-4718-a8b5-52738bf5ed9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f460015-95cf-459f-8103-93af349cc6d8",
   "metadata": {},
   "source": [
    "4.1) Based on the predictions, we can calculate the **accuracy**, i.e. how often the model voted for the correct class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162a66f5-36dc-4503-bfe7-1fe725bb5da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy    = 100*(Test['label'] == predictions).sum()/len(predictions)\n",
    "print(f'accuracy = {accuracy: .2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4944ea4-7646-4321-9bc1-e9c23bfef5a2",
   "metadata": {},
   "source": [
    "An accuracy of 84% is a relatively good result, considering the overlap between \"Toxic\" and \"Non-Toxic\" molecules we saw in earlier modules."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996896c2-4321-4bf0-890b-75a956b51c48",
   "metadata": {},
   "source": [
    "4.2) But the accuracy gives us only limited information. Therefore we generate a **confusion matrix** as discusssed in the lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd021e6-e01a-4d99-88a2-df67b19b8e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = ['Non-Toxic', 'Toxic']\n",
    "\n",
    "cm   = confusion_matrix(Test['label'], predictions, labels = L, normalize = 'true')\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = L)\n",
    "disp.plot(cmap = 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9157b96-a737-4818-bb7b-c2679cbbd2f2",
   "metadata": {},
   "source": [
    "4.3) An even more detailed evaluation of the model performance can be obtained by generating a histogram of the probabilities the model voted for the correct label - a so called **cross entropy** plot. Ideally, this plot shows a clear peak at $p = 1$ for the true label for each class. That is usually not the case and we can thereby see if the model struggles with particular classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f20c15b-33fd-4711-b8cd-6d19fbb7c7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "PredProbs = np.vstack((predProbs, 1 - predProbs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5575fa-581b-417b-a4a0-5e901ec23aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(len(L), 1, sharex = True)\n",
    "fig.set_figheight(6)\n",
    "fig.subplots_adjust(hspace = 0.5)\n",
    "fig.suptitle('entropy')\n",
    "\n",
    "for i, l in enumerate(L):\n",
    "    idx = [k for k, y in enumerate(Test['label']) if y == l]\n",
    "    idx = np.array(idx)\n",
    "    (value, where) = np.histogram(PredProbs[i,idx], bins = np.arange(0, 1, 0.01), density = True)\n",
    "    w = 0.5*(where[1:] + where[:-1])\n",
    "    ax[i].plot(w, value, 'k-')\n",
    "    ax[i].set_ylabel('frequency')\n",
    "    ax[i].set_title(l)\n",
    "ax[len(L)-1].set_xlabel('probability')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
