{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cba9749-fcbe-4e10-8353-37ec1d002e71",
   "metadata": {},
   "source": [
    "# Dimension Reduction\n",
    "## and naive Bayes\n",
    "\n",
    "(molecule data set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3d350b-4b3b-492e-afb1-7e4e88e9ac7a",
   "metadata": {},
   "source": [
    "As with the artificial dataset, we first want to walk through the analysis pipeline, which performs the following steps:<br> \n",
    "<br>\n",
    "1) Loading the molecule data set *\"molecular_test_gbc.xlsx\"* and *\"molecular_train_gbc.xlsx\"*<br>\n",
    "2) Creating a plot showing Pearsons' correlation of all features in *\"molecular_train_gbc.xlsx\"* in a heatmap and a UMAP plot<br>\n",
    "3) Scaling and normalizing the dataset, before running a PCA<br>\n",
    "4) Finally using NaiveBayes for classification<br>  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39287359-b408-425f-a0b8-1357a7cb8ba7",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67d11d6-c534-4536-a74d-eaba4ccc30dc",
   "metadata": {},
   "source": [
    "**0) Loading libraries**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4cde188-dc3a-409d-9eba-329eafbfba55",
   "metadata": {},
   "source": [
    "We load our standard libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613bd6cd-065e-47a5-bfcd-eefd0d867718",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9991c99b-e1cb-4547-8f49-216083c6ceb7",
   "metadata": {},
   "source": [
    "Another useful tool to map high dimensional data into a 2D or 3D plot is UMAP (see office hour if interested into details). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cc5f9a-fc35-42df-9806-43a2f68a3cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap.umap_ as umap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194a96b7-7cb2-46bc-8a82-6e2c3df344f3",
   "metadata": {},
   "source": [
    "Finally, we import the libraries needed for performing Naive Bayes, PCA and normalization of the dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4b0685-039f-4982-ba6c-9a58e69863b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import *\n",
    "from sklearn.decomposition import PCA\n",
    "from plot_entropy_and_confusion import *\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef33116-0aad-4e39-ad7b-85e137026297",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abdce139-aacb-4679-a971-2113edf2333d",
   "metadata": {},
   "source": [
    "**1) Reading the data set**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff4b8e8-9b84-4415-a640-b1097c7414ac",
   "metadata": {},
   "source": [
    "We read the training dataset for training the model, the test dataset for evaluating model performance and separate the features *X* and the labels *Y*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef33548c-7b50-4ad7-92b5-8d8b6d0d1fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train  = pd.read_csv('molecular_train_gbc.csv')\n",
    "TrainY = Train['label']\n",
    "TrainX = Train.drop('label', axis = 1)\n",
    "\n",
    "Test   = pd.read_csv('molecular_test_gbc.csv')\n",
    "TestY  = Test['label']\n",
    "TestX  = Test.drop('label', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9072b98a-417b-42ea-b1a9-115ee68d42a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ea8960-776a-4aa7-8c76-0768d01332be",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa9827a-b071-485e-ae62-a488440c4157",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23fc952-1210-416c-a8c5-513b2a243653",
   "metadata": {},
   "source": [
    "**2) Plotting the data set**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07668df1-0f58-442d-be15-a02198e85c36",
   "metadata": {},
   "source": [
    "Since we have a dataset with five features, an ordinary 3D plot is not possible. However, we still can plot the correlation values. We also want to plot each feature against eachother."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4cfbb7-7a3a-44bc-ace0-0e38eb4d8623",
   "metadata": {},
   "source": [
    "2a) Pearsons Correlation Coefficient "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54178204-aa43-432b-bc98-b50e49e9247b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(TrainX.corr(), annot=True, cmap = sns.color_palette(\"Blues\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0f124f-93bc-4f9d-8a70-aebec027f4bc",
   "metadata": {},
   "source": [
    "2b) Each feature vs eachother"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8f6b4d-ada9-4db1-9838-7b4f126076a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = sns.pairplot(TrainX, kind = \"kde\", \\\n",
    "                   plot_kws = {'color':[176/255,224/255,230/255]}, \\\n",
    "                   diag_kws = {'color':'black'})\n",
    "out.map_offdiag(plt.scatter, color = 'black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec89142-3e23-4250-b9c5-690680f79b01",
   "metadata": {},
   "source": [
    "As we can see, the features are highly correlated. Finally, we want to project the 5D dataset into 3D using UMAP (note, that this is no analysis yet)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f190ce7-7327-4ecc-8085-e95ad79c48e6",
   "metadata": {},
   "source": [
    "2c) UMAP plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbfdc09-e593-4921-893c-019fc4f879f3",
   "metadata": {},
   "source": [
    "First we scale the data set as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bda6871-425e-4c4f-8723-60c1d33e3a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler  = MinMaxScaler(feature_range=(0, 1)) \n",
    "TrainXS = scaler.fit_transform(TrainX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1609ef75-a036-4146-9883-6ccfe6b41b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainX_UMAP = umap.UMAP(n_components = 3).fit_transform(TrainXS) #5D --> 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f3198a-42f0-4306-8443-9d86845b0a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "colorsIdx = {'Non-Toxic': 'black', 'Toxic': 'red'}\n",
    "cols      = TrainY.map(colorsIdx)\n",
    "\n",
    "scatter = go.Scatter3d(x = TrainX_UMAP[:,0], y = TrainX_UMAP[:,1], z = TrainX_UMAP[:,2], mode = 'markers', marker = dict(size = 3, color = cols))\n",
    "fig     = go.Figure(data = [scatter])\n",
    "fig.update_layout(width = 800, height = 800, margin = dict(r = 10, b = 10, l = 10, t = 10))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48003861-3161-4b5e-a71f-40a002684f17",
   "metadata": {},
   "source": [
    "In the last plot, we can't really see cluster according to the labels. Therefore, let's scale the data and run a PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1eba73-8b60-4532-a36a-ae842abd6f69",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8109e4-d990-4974-9e85-18e0c325f94a",
   "metadata": {},
   "source": [
    "**3) Scaling & PCA**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f40815-cee6-473b-b0c8-1d621a6f6c10",
   "metadata": {},
   "source": [
    "Before performing any analysis, we have to scale the test dataset the same way we scaled the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daad4f25-1f6c-4350-bd7b-0a10a8896624",
   "metadata": {},
   "source": [
    "3a) Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d0eb41-4941-479a-a54c-69833ad8b123",
   "metadata": {},
   "outputs": [],
   "source": [
    "TestXS = scaler.transform(TestX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef43dd6-ff01-48fa-a7d0-c3d56dc467a2",
   "metadata": {},
   "source": [
    "3b) PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c33540-e71c-4917-8d07-ffee7918b5bc",
   "metadata": {},
   "source": [
    "Now, we perform the actual PCA with the training data using *fit* for setting up our model and *transform* for transforming the data into the eigenspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0f23fb-ef9e-4633-a8e5-fa856d3487bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = PCA(n_components = 5).fit(TrainXS) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cfda3a-aec7-42dc-a947-a5d4674215cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenVec    = out.components_\n",
    "eigenVal    = out.explained_variance_\n",
    "eigenTrainX = out.transform(TrainXS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80dbfd7a-9ec6-4433-9a00-09b9680b2e26",
   "metadata": {},
   "source": [
    "Plotting eigenvalue spectrum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b033c5e8-1251-4af3-ad35-fb90d83c4537",
   "metadata": {},
   "outputs": [],
   "source": [
    "xplot    = np.arange(1,6)\n",
    "\n",
    "fig = plt.figure(figsize=(5, 3))\n",
    "plt.bar(xplot, eigenVal, color = (0.9, 0.9, 0.9), edgecolor = 'black')\n",
    "plt.xlabel('dimension')\n",
    "plt.ylabel('eigenvalue')\n",
    "plt.yscale('log')\n",
    "plt.xticks(xplot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba8a0ee-5395-4000-97eb-073fed92d7b2",
   "metadata": {},
   "source": [
    "We see, that three features are sufficient in order to analyze the data, since two of the eigenvalues are significant smaller than the other three eigenvalues.<br>\n",
    "Now, we first check the correlation heatmap and then create a plot of the scaled and PCA corrected data. This time we can create a scatter plot of the actual data, since we only need three dimensions now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44894a0f-c88b-4040-88dc-4c37507018b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(pd.DataFrame(eigenTrainX).corr(), annot=True, cmap = sns.color_palette(\"Blues\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1ecb3a-1cc4-4986-99cc-a02660eab8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "colorsIdx = {'Non-Toxic': 'black', 'Toxic': 'red'}\n",
    "cols      = TrainY.map(colorsIdx)\n",
    "\n",
    "scatter = go.Scatter3d(x = eigenTrainX[:,0], y = eigenTrainX[:,1], z = eigenTrainX[:,2], mode = 'markers', marker = dict(size = 5, color = cols))\n",
    "fig     = go.Figure(data = [scatter])\n",
    "fig.update_layout(width = 800, height = 800, margin = dict(r = 10, b = 10, l = 100, t = 10))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1b8f6f-0b86-4c1c-8d00-7839f8051b33",
   "metadata": {},
   "source": [
    "Eventough there are no well separated clusters visible, we at least find a tendency of the toxic molecules being on another part of the data space compared to to non-toxic molecules. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105cce45-36d1-4a07-a2e5-3a7686b01d93",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6670a6-76fb-4070-a4fc-357664da2e45",
   "metadata": {},
   "source": [
    "**4) Naive Bayes**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c9bbad-6fc1-4433-80b2-c353e842c17c",
   "metadata": {},
   "source": [
    "We have scaled and de-correlated the data. In the next step, we can now apply naive Bayes and check the result using the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10c5a87-2ce3-4d19-9243-04ca33412279",
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenTestX  = out.transform(TestXS)  #performing PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7895793c-54bd-49db-a516-4c1e228fd5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb   = GaussianNB()\n",
    "Ypred = gnb.fit(eigenTrainX, TrainY).predict(eigenTestX)\n",
    "Probs = gnb.predict_proba(eigenTestX) #probabilities per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3645e8d-e1e7-4ebe-89dc-7d47982d7de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = (Ypred == TestY).sum()/len(Ypred)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6051bc68-63dd-4df4-94f1-8b11cb93a5cc",
   "metadata": {},
   "source": [
    "Finally, we generate an entropy plot and a confusion matrix as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305a29f4-00af-4034-99b9-5a4f294b6e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "ClassLabs = ['Non-Toxic', 'Toxic']\n",
    "#we have only two classes and label \"Toxic\" to zero and \"Non-Toxic\" to 1\n",
    "Ynum      = [0 if i == 'Non-Toxic' else 1 for i in TestY]\n",
    "YPrednum  = [0 if i == 'Non-Toxic' else 1 for i in Ypred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a179cbd-4e52-43c0-8b69-037bd2e65a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion(YPrednum, Ynum, ClassLabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cad9b71-903d-44c5-8879-665274338fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ClassLabsNum = [0, 1]\n",
    "plot_entropy(Probs, Ynum, ClassLabs, ClassLabsNum)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
