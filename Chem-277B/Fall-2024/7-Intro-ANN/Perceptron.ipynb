{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aafc06e9-e354-4534-b8b7-cbb2b24c0096",
   "metadata": {},
   "source": [
    "## Building a Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e73d9ac-ae6e-4580-ba60-b6987ded86e2",
   "metadata": {},
   "source": [
    "**0) Loading and Preparing Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0f7e48-47fd-4b33-8e55-467fbdaeb8ab",
   "metadata": {},
   "source": [
    "Importing libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2375136-822f-464d-9cec-94b072310497",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25113b3-5738-4fa9-a876-66100c534c41",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5729ea-c3f8-470a-8763-04acc0fb881d",
   "metadata": {},
   "source": [
    "Importing the iris dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22523517-ea4d-49de-934d-115c4e11fbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris  = datasets.load_iris()\n",
    "names = iris.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a13b41-ae4b-4d49-a8fa-f47a9a5034f1",
   "metadata": {},
   "source": [
    "We want to start with two classes only: Setosa and \"not Setosa\"..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58cf14b-fdf5-46e3-bd10-4a31aa9e8f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mult  = [50,50,50]\n",
    "\n",
    "Target = []\n",
    "for n, m in zip(names, mult):\n",
    "    Target.extend([n] * m)\n",
    "\n",
    "indices = [i for i, x in enumerate(Target) if x == 'setosa']\n",
    "\n",
    "Targetnum          = iris.target*0\n",
    "Targetnum[indices] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a504e415-4c41-4211-aaec-5f6f5b339cb1",
   "metadata": {},
   "source": [
    "...and also with two features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a526a2-5985-4794-b640-24aa98363a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X    = iris.data\n",
    "X2D  = X[:,1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2c5ea0-af12-4c15-8a62-4452d6950a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb750548-991a-4296-b664-90d591cc225d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51087546-06fc-4f71-9c5a-a4f12eee494a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b96cf7b-98c6-42aa-a7da-b0810285c58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Targetnum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0248279e-90d6-41da-be06-fb24e1cba3b2",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496638a8-fba2-4846-ba6f-9b84eaf84423",
   "metadata": {},
   "source": [
    "**1) Building the Neuron/Perceptron**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b80e26-a95a-4d33-98d6-5af0aebd01e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def Neuron1(Data, Target, alpha = 0.01):\n",
    "    \n",
    "#Data   :          the input matrix\n",
    "#Target :          the target vector t for E = 0.5*(t - y)**2\n",
    "#alpha  :          learning rate    \n",
    "\n",
    "    if len(Target.shape) == 1:\n",
    "        Target = Target.reshape(len(Target),1)\n",
    "\n",
    "    [rows, cols] = Data.shape\n",
    " \n",
    "    N = rows #N: Number of observations\n",
    "    I = cols #I: Number of input channels\n",
    "\n",
    "    #initializing weights incl bias:\n",
    "    W     = np.random.normal(-1,1,(I + 1,1))\n",
    "\n",
    "    #adding bias column (see slides)\n",
    "    bias  = np.ones((N,1))\n",
    "    Input = np.hstack((Data, bias))\n",
    "\n",
    "    #calculating prediction\n",
    "    net   = np.dot(Input, W)    #net output\n",
    "    Y     = 1/(1 + np.exp(-net))#activation here: sigmoid\n",
    "\n",
    "    #target vs output\n",
    "    Error     = Target - Y\n",
    "    \n",
    "    #backpropagation\n",
    "    dY     = Y*(1 - Y)\n",
    "    dE     = Error\n",
    "    \n",
    "    W[:-1] = W[:-1] - alpha*np.dot(-Input[:,:-1].transpose(), dY*dE) #for weights\n",
    "    W[-1]  = W[-1]  - alpha*np.dot(-dY.transpose(), dE)              #for bias\n",
    "\n",
    "    return W"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e581d18-1265-48b0-8fe5-88137ac72be9",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a591f57e-e11e-4b54-944a-35867a4dca66",
   "metadata": {},
   "source": [
    "Let us run the neuron for X and X2D and check the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980c7487-ca79-4fbb-9c5c-b5f9930cad24",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = Neuron1(X2D,Targetnum)\n",
    "print(W) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a8ce5d-d485-44c2-b5be-2bb1a88420e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = Neuron1(X,Targetnum)\n",
    "print(W) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3715d81e-3397-48ca-8e7f-51889c4e2ed0",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5447e23a-d3cf-4bd3-b0e5-43cf9060e011",
   "metadata": {},
   "source": [
    "Now we want to see, if the weights converge and the error reduces if we run the code for many iterations. First we need to set the number of iterations as an input argument and then run a *for* loop within the neuron. Next, we add a plotting part at the end of the function to illustrate the changes of the weights, the bias and the error, hence the learning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b3b824-4f44-4b5f-91ff-00d0fb1db53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def Neuron2(Niter, Data, Target, alpha = 0.01):\n",
    "\n",
    "#Niter  :          number of iterations    \n",
    "#Data   :          the input matrix\n",
    "#Target :          the target vector t for E = 0.5*(t - y)**2\n",
    "#alpha  :          learning rate   \n",
    "\n",
    "    if len(Target.shape) == 1:\n",
    "        Target = Target.reshape(len(Target),1)\n",
    "        \n",
    "    [rows, cols] = Data.shape\n",
    " \n",
    "    N = rows #N: Number of observations\n",
    "    I = cols #I: Number of input channels\n",
    "\n",
    "    #initializing weights incl bias:\n",
    "    W     = np.random.normal(-1,1,(I + 1,1))\n",
    "\n",
    "    #adding bias column (see slides)\n",
    "    bias  = np.ones((N,1))\n",
    "    Input = np.hstack((Data, bias))\n",
    "\n",
    "    MSE   = np.zeros((Niter,1))  #monitoring E\n",
    "    Wei   = np.zeros((Niter,I + 1))#monitoring weights and bias\n",
    "\n",
    "    for n in range(Niter):\n",
    "\n",
    "        #calculating prediction\n",
    "        net   = np.dot(Input, W)    #net output\n",
    "        Y     = 1/(1 + np.exp(-net))#activation here: sigmoid\n",
    "    \n",
    "        #target vs output\n",
    "        Error     = Target - Y\n",
    "        \n",
    "        #backpropagation\n",
    "        dY     = Y*(1 - Y)\n",
    "        dE     = Error\n",
    "        \n",
    "        W[:-1] = W[:-1] - alpha*np.dot(-Input[:,:-1].transpose(), dY*dE) #for weights\n",
    "        W[-1]  = W[-1]  - alpha*np.dot(-dY.transpose(), dE)              #for bias\n",
    "\n",
    "        #saving results    \n",
    "        MSE[n]   = sum(Error**2)/N\n",
    "        Wei[n,:] = W.transpose()\n",
    "\n",
    "    \n",
    "########plotting#################################################################\n",
    "\n",
    "    fig, axs = plt.subplots(2, 1)\n",
    "    axs[0].plot(range(Niter), MSE, c = 'black', linewidth = 3)\n",
    "    axs[0].set_title('MSE')\n",
    "    axs[0].set_xlabel('iteration')\n",
    "    axs[0].set_yscale('log')\n",
    "    axs[1].plot(range(Niter), Wei, linewidth = 3)\n",
    "    axs[1].set_title('weights')\n",
    "    axs[1].set_xlabel('iteration')\n",
    "    fig.tight_layout(pad = 1.0)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    return Wei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f6db44-9b01-4533-b09e-21a218a2a3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Wei = Neuron2(5000, X2D, Targetnum) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce51dcea-d56a-4c04-9bb5-ba53d2a18a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "Wei = Neuron2(5000, X, Targetnum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb493d4-0ede-4240-824c-db606ca5d58a",
   "metadata": {},
   "source": [
    "We see that for most runs, the error reduces and the weights converge. But in some cases the neuron doesn't seem to find a good minimum. This is because we neither have implemented an adaptive learning rate, nor a momentum or any regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3989ca-c598-4cc4-9cd1-bf5149252e7e",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1945b161-3246-40a9-9179-81b71c232808",
   "metadata": {},
   "source": [
    "We still want to understand the learning process in more detail. Run the function NeuronContour.py for different numbers of iterations and explore how the threshold emerges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b6b8ca-4aaa-4675-9945-55bfb1fb1b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def NeuronContour(Niter, Data, Target, alpha = 0.01):\n",
    "\n",
    "#Niter  :          number of iterations    \n",
    "#Data   :          the input matrix\n",
    "#Target :          the target vector t for E = 0.5*(t - y)**2\n",
    "#alpha  :          learning rate\n",
    "\n",
    "    #creating meshgrid through the data range for illustration\n",
    "    Ngrid = 100\n",
    "\n",
    "    x1 = np.linspace(Data[:,0].min(), Data[:,0].max(), Ngrid)\n",
    "    x2 = np.linspace(Data[:,1].min(), Data[:,1].max(), Ngrid)\n",
    "    \n",
    "    [xx1, xx2] = np.meshgrid(x1, x2)\n",
    "\n",
    "\n",
    "    if len(Target.shape) == 1:\n",
    "        Target = Target.reshape(len(Target),1)\n",
    "        \n",
    "    [rows, cols] = Data.shape\n",
    " \n",
    "    N = rows #N: Number of observations\n",
    "    I = cols #I: Number of input channels\n",
    "\n",
    "    #initializing weights incl bias:\n",
    "    W     = np.random.normal(-1,1,(I + 1,1))\n",
    "\n",
    "    #adding bias column (see slides)\n",
    "    bias  = np.ones((N,1))\n",
    "    Input = np.hstack((Data, bias))\n",
    "\n",
    "\n",
    "    for n in range(Niter):\n",
    "\n",
    "        #calculating prediction\n",
    "        net   = np.dot(Input, W)    #net output\n",
    "        Y     = 1/(1 + np.exp(-net))#activation here: sigmoid\n",
    "    \n",
    "        #target vs output\n",
    "        Error     = Target - Y\n",
    "        \n",
    "        #backpropagation\n",
    "        dY     = Y*(1 - Y)\n",
    "        dE     = Error\n",
    "        \n",
    "        W[:-1] = W[:-1] - alpha*np.dot(-Input[:,:-1].transpose(), dY*dE) #for weights\n",
    "        W[-1]  = W[-1]  - alpha*np.dot(-dY.transpose(), dE)              #for bias\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "########plotting#################################################################\n",
    "    XY        = np.c_[xx1.ravel(), xx2.ravel()]\n",
    "    L         = XY.shape[0]\n",
    "    Inputcont = np.hstack((XY, np.ones((L,1))))\n",
    "    netcont   = np.dot(Inputcont, W)\n",
    "    Ycont     = 1/(1 + np.exp(-netcont))\n",
    "    Ycont     = Ycont[:,0:2].reshape(Ngrid,Ngrid)\n",
    "    Y         = np.round(Y)\n",
    "    \n",
    "    IdxTrue0 = np.argwhere(Target == 0)\n",
    "    IdxTrue1 = np.argwhere(Target == 1)\n",
    "    \n",
    "    IdxPred0 = np.argwhere(Y == 0)\n",
    "    IdxPred1 = np.argwhere(Y == 1)\n",
    "\n",
    "    CM = \"Blues\"\n",
    "    \n",
    "    plt.contourf(xx1, xx2, Ycont, cmap = CM, alpha = 0.3, levels = 100)\n",
    "    plt.scatter(Data[IdxTrue0, 0], Data[IdxTrue0, 1], color = [255/256,69/256,0], marker = '.')\n",
    "    plt.scatter(Data[IdxTrue1, 0], Data[IdxTrue1, 1], color = [46/256,139/256,87/256], marker = '.')\n",
    "    plt.scatter(Data[IdxPred0, 0], Data[IdxPred0, 1], edgecolors = [255/256,69/256,0], marker = 'o', facecolors = 'none')\n",
    "    plt.scatter(Data[IdxPred1, 0], Data[IdxPred1, 1], edgecolors = [46/256,139/256,87/256], marker = 'o', facecolors = 'none')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d99aabd-f6d8-405f-8e9e-7b871e8f4084",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3270e860-f326-412a-b8fa-282aaf7cdd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "NeuronContour(3, X2D, Targetnum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e49492-1b6e-4252-9c1e-9a17cfe94a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "NeuronContour(5, X2D, Targetnum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6b96f6-8855-4c40-b83d-4ae795323a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "NeuronContour(100, X2D, Targetnum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ab6bd9-5544-467c-b926-673752d0c412",
   "metadata": {},
   "outputs": [],
   "source": [
    "NeuronContour(10000, X2D, Targetnum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3dfc07-7c8f-4cda-9a6c-35793d1dfa01",
   "metadata": {},
   "source": [
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
