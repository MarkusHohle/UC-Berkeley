{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59c618c3-a50b-4b7a-8611-043670640ec0",
   "metadata": {},
   "source": [
    "## LSTM Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c89d13-fad7-443e-81fb-e0894b443594",
   "metadata": {},
   "source": [
    "We want to train an univariate, one feature LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960bdad6-9657-4d5c-b96d-7d888e59c5ef",
   "metadata": {},
   "source": [
    "**0) Loading Libraries and Subroutines**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98acc91f-f3da-4c05-be20-ce803b1c564f",
   "metadata": {},
   "source": [
    "Standard libraries for plotting and numerical operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10ab194-3b21-45c7-8387-aafd39ad3691",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90050234-9bfe-46aa-8d54-7226e6bef06e",
   "metadata": {},
   "source": [
    "Loading LSTM related keras libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2245f694-3281-4e77-98bc-3641fca8aae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7be23df-b658-4560-9f9f-0b95486bf5b1",
   "metadata": {},
   "source": [
    "Calling a subroutine that puts data set in the correct shape for LSTM (see later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce62fba-0ff4-4b93-bdcf-576610421807",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prepare_data import prepare_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca37431-93b4-44ee-a0e8-d475c5d80dc6",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e305239-47f7-4299-999c-990d1f1d2911",
   "metadata": {},
   "source": [
    "**1) Generating a Simple Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d483fb87-1d0b-4712-944c-242a184b71e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_start = -50\n",
    "t_end   = 10\n",
    "incr    = 0.25\n",
    "\n",
    "t       = np.arange(t_start, t_end, incr)\n",
    "t       = t.reshape(len(t), 1)\n",
    "Y_t     = np.sin(t) + 0.1*np.random.randn(len(t), 1) + np.exp((t + 20)*0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9402644-1811-48c5-a41c-1169fdd21391",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(t, Y_t)\n",
    "plt.title('complete series')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b7b113-e556-43f5-aca1-1a4fb93df077",
   "metadata": {},
   "source": [
    "**2) Preprocessing the Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3260bff7-10f9-4c19-9c84-93922ba33f96",
   "metadata": {},
   "source": [
    "2a) Scaling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd712503-a991-470d-a174-fb34cb8ec961",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler  = MinMaxScaler(feature_range = (0, 1))\n",
    "Y_tnorm = scaler.fit_transform(Y_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319aa0b1-4350-4fc9-ab99-a12fc1f7d107",
   "metadata": {},
   "source": [
    "2b) Reshaping the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc90a7f6-197a-4539-9ee0-ab34a36014c9",
   "metadata": {},
   "source": [
    "The dataset has only one feature. We want to predict *dt_futu* data points into the future and train the LSTM with the previous *dt_past* time steps to predict the next. For that purpose, we need to reshape the data in such a way that *dt_futu* is interpreted as features. Therefore, we run the following subroutine:<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9ce64a-55bd-4c2e-bce4-375ed1d810f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_past    = 20\n",
    "dt_futu    = 8\n",
    "n_features = 1\n",
    "\n",
    "[X, Y] = prepare_data(Y_tnorm, dt_past, dt_futu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a095c5-8fe6-4888-afee-ff65efcf3cef",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f266f5-8674-4cd4-be29-306d3927b941",
   "metadata": {},
   "source": [
    "Let us check the shapes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11446a10-0092-4bda-b064-a0d1bb995ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y_tnorm.shape)\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c35040-c63b-4f1a-9a56-6b0d1170ede7",
   "metadata": {},
   "source": [
    "In order to train the LSTM with $dt_{futu}$ and $dt_{past}$, we need the first $dt_{past}$ steps in order to train for the next prediction. The lenght of the period we want to predict is $dt_{futu}$. The last step in the training will be the point, when we predict the last sequence $dt_{futu}$ with the previous steps $dt_{past}$. Thus, the training data set has the length $len\\left(Y_{tnorm}\\right) - dt_{past} - dt_{futu} + 1$. Each time point in the past we need for the prediction will have its own influence on the future and therefore are regarded as feature. Thus, $X$ has to have the shape $\\left[len\\left(Y_{tnorm}\\right) - dt_{past} - dt_{futu} + 1\\right] \\times dt_{past}$.<br>   \n",
    "Because of that interpretation, each feature is shifted by one time point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d8315d-2d82-41bc-9506-52be7df457df",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X[:dt_past, :dt_past, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a829d8-8b6a-4b8c-8543-8925e7665f4d",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4e1177-5e80-4b5d-89e4-1acb1a1fc5b1",
   "metadata": {},
   "source": [
    "Following the same logic, in order to train the LSTM to predict the future $dt_{futu}$ ahead, $Y$ needs to have the same structure: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5e196b-8c80-47e2-82c8-f960a26b8571",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y[:dt_futu, :dt_futu, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a930ec-6cf3-47b7-b564-369faca6a224",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b71849-bc60-46c5-8351-e65acf5c8787",
   "metadata": {},
   "source": [
    "2c) Splitting data into Training and Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e0c719-bff7-4e41-a18c-9a226120b8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut            = int(np.round(0.7*Y_tnorm.shape[0]))\n",
    "\n",
    "TrainX, TrainY = X[:cut], Y[:cut]\n",
    "TestX,   TestY = X[cut:], Y[cut:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9bb98d-0ccb-40bf-a2b6-b13d5933e1a9",
   "metadata": {},
   "source": [
    "Just to make sure, that the shape is *len(X) x dt_past x n_features*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfd5ea9-e363-4fdc-bb8b-b12452063b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(TrainX.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000836d4-7d77-4820-98f9-de445c3487a1",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697bb035-9d4d-4afa-aacc-c637e80dc731",
   "metadata": {},
   "source": [
    "**3) Creating the Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c0dfce-5e95-4632-867f-70479c82c2cc",
   "metadata": {},
   "source": [
    "Creating a LSTM in Python follows the same syntax as for CNNs. We want to predict data points in the future, based on previous data points. Therefore, we need to solve a **regression** problem:<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ab735e-3b3a-4560-94a9-13ac117280f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_neurons  = 400\n",
    "batch_size = 128\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(n_neurons, input_shape = (dt_past, n_features), activation = 'tanh'))\n",
    "model.add(Dense(dt_futu))\n",
    "\n",
    "opt = optimizers.Adam()\n",
    "model.compile(loss = 'mean_squared_error', optimizer = opt)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c657ee60-4a60-44ee-8bcd-c31592309138",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ae7a81-b89e-413f-a179-104a157721b6",
   "metadata": {},
   "source": [
    "**4) Running the Fit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c8cf7a-0619-4107-85cf-4a89c197fe09",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 800\n",
    "out = model.fit(TrainX, TrainY, epochs = n_epochs, batch_size = batch_size, validation_split = 0.2, verbose = 2, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a87c15e-58fa-4d82-9532-0b5893ea734f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting #############################################################\n",
    "plt.plot(out.history['loss'])\n",
    "plt.plot(out.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc = 'upper left')\n",
    "plt.savefig('training loss.pdf')\n",
    "plt.show()\n",
    "#######################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ea4f73-4732-406d-af20-da678e62a51d",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5055ad5-85e1-4f6c-8e06-b99b117e4f38",
   "metadata": {},
   "source": [
    "**5) Evaluating the Fit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f03886a-1d4d-4ce1-8c9e-db63db83a39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PredY = model.predict(TestX)\n",
    "back  = PredY.shape[0]\n",
    "\n",
    "plt.plot(t, Y_tnorm, linewidth = 5)\n",
    "plt.plot(t[-back:], PredY[:, dt_futu-1])\n",
    "plt.legend(['actual data', 'prediction'])\n",
    "plt.fill_between([t[-back,0], t[-1,0]], 0, 1, color = 'k', alpha = 0.1)\n",
    "plt.plot([t[-back,0], t[-back,0]], [0, 1], 'k-', linewidth = 3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de34e51-c123-426b-a9db-9df1e13b2762",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(PredY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad68e77-758a-49ac-8ab4-90cc8c6d65d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(TestX.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
