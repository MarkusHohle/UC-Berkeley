{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99ed50b5-0671-4f0a-bfbf-d15c3ff60268",
   "metadata": {},
   "source": [
    "## Example Naive Bayes in Python<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3647e1-8ea4-4f8b-ba78-572286a0f6ef",
   "metadata": {},
   "source": [
    "**0) Loading Libraries**<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f051da-4fff-472c-a6d2-1481ef78ad4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#standard libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2564a4-54f4-4aac-ad97-c2b21af7ab4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import *                              #importing libraries for Naive Bayes analysis\n",
    "from sklearn.preprocessing import MinMaxScaler                 #we need to scale the data in order to avoid numerical bias \n",
    "from plot_entropy_and_confusion import *                       #after fitting, we want to evaluate the model using a confusion chart and an entropy plot\n",
    "from umap import UMAP                                          #we work with a highdimensional data set. In order to plot the data, we can project it\n",
    "                                                               #to two or three dimensions using UMAP (run \"pip install umap-learn\" if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0909d1df-14f1-4a95-8423-048e4b3ecbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install plotly\n",
    "import plotly.graph_objects as go                              #finally, we want to use plotly in order to generate an interactive plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a61616-0928-453d-b391-930aeccbe782",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086b5bf8-9220-4bf3-b9ea-fc462daaffe9",
   "metadata": {},
   "source": [
    "**1) Loading and Inspecting the Data**<br>\n",
    "<br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1a3f5ae5-732f-43fd-a434-9eed9566cc69",
   "metadata": {},
   "source": [
    "We read the molecule dataset that we know already. There are two sets: the training set and the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82768f58-f3c4-4c7e-9903-27743336957e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train = pd.read_csv('molecular_train_gbc_cat.csv')\n",
    "Test  = pd.read_csv('molecular_test_gbc_cat.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b26e8c-8f2e-4fc1-8215-81539d3501a9",
   "metadata": {},
   "source": [
    "The dependent variable is categorical. We have two classes: toxic and non-toxic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f9dd46-e5fd-4716-8963-660caa77c8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225bdbd5-9991-4026-9290-d39b57ec78ec",
   "metadata": {},
   "source": [
    "<br>\n",
    "Let us now plot the data by using UMAP as a dimension reduction method. First, we extract X (the freatures) and Y (the labels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92009456-b38b-4d45-bcc2-0cffe290fc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrain = Train.drop('label', axis = 1).values\n",
    "YTrain = Train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78cf6ed-738b-47a2-bd7a-8d8d8e1793a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(YTrain[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fffcdbe-eda3-461d-acb7-939ae51ffc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(XTrain[:10,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1f337d-478e-43dd-8cb2-3abb69532160",
   "metadata": {},
   "source": [
    "Let us plot histograms of a few features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef83c9d-58e7-46bf-b803-93ca73762e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(Train[['molecular_weight']], x = \"molecular_weight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835d40b8-fc07-490f-8a30-f6adb0937961",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(Train[['electronegativity']], x = \"electronegativity\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9cb9d4-b3cf-41b2-9712-d90a8e7eb769",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392113a3-021c-481c-a3ed-f47238b6fcfb",
   "metadata": {},
   "source": [
    "**2) Plotting the Data**<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bcfc60-028e-4a44-9feb-e12ae5e68bda",
   "metadata": {},
   "source": [
    "Scaling and normalizing the data is important for the fitting procedure. But we also want to make sure, that it doesn't affect the UMAP transformation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60e996a-d245-4817-94d5-1927405e37e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler   = MinMaxScaler(feature_range = (0, 1)) \n",
    "XTrainS  = scaler.fit_transform(XTrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfe1ad3-e125-408d-a768-b5712d3fd389",
   "metadata": {},
   "source": [
    "Next, we run the UMAP transformation from 5D to 3D and then generate a scatter plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7027b8bc-d6b6-44eb-984f-f6831c572036",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit    = UMAP(n_components = 3)\n",
    "XTrans = fit.fit_transform(XTrainS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcb5a96-f25e-407d-9526-f68a4945f373",
   "metadata": {},
   "source": [
    "Plotting in 3D:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5bd632-6dd3-4ed2-82b5-aa2ea084bd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "colorsIdx = {'Non-Toxic': 'black', 'Toxic': 'red'}\n",
    "cols      = YTrain.map(colorsIdx)\n",
    "\n",
    "scatter = go.Scatter3d(x = XTrans[:,0], y = XTrans[:,1], z = XTrans[:,2], mode = 'markers', marker = dict(size = 5, color = cols))\n",
    "fig     = go.Figure(data = [scatter])\n",
    "fig.update_layout(width = 800, height = 800, margin = dict(r = 10, b = 10, l = 100, t = 10))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ca11fd-26ba-4d0f-9cf5-16d53a03d99e",
   "metadata": {},
   "source": [
    "Let us also compare the scaled data to the raw data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49588bb3-82c6-4112-b2e5-dd3b634c5138",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(XTrainS[:10,:])#scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef212a5d-78ac-4a7d-8fef-3919d4269350",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(XTrain[:10,:])#raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba77c7d-ffb8-49de-be33-2cbbbda37581",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(XTrainS[:,1], 20)\n",
    "plt.xlabel('electronegativity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95852487-2d58-4693-afff-3c49b8808833",
   "metadata": {},
   "source": [
    "As a test, we can run the projection without having scaled the data first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f856e41-55ac-4cf8-8d0e-277848a4a425",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit    = UMAP(n_components = 3)\n",
    "Xtrans = fit.fit_transform(XTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876a2fdd-b846-45f9-8762-64238c9bc094",
   "metadata": {},
   "outputs": [],
   "source": [
    "colorsIdx = {'Non-Toxic': 'black', 'Toxic': 'red'}\n",
    "cols      = YTrain.map(colorsIdx)\n",
    "\n",
    "scatter = go.Scatter3d(x = Xtrans[:,0], y = Xtrans[:,1], z = Xtrans[:,2], mode = 'markers', marker = dict(size = 5, color = cols))\n",
    "fig     = go.Figure(data = [scatter])\n",
    "fig.update_layout(width = 800, height = 800, margin = dict(r = 10, b = 10, l = 100, t = 10))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de04ee5b-c3fb-4a0c-9e60-59b9a77afa22",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51233878-8641-44a9-b705-a562f53a417a",
   "metadata": {},
   "source": [
    "**3) Naive Bayes**<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e280ee9b-56c0-437d-b292-a937b9697fdc",
   "metadata": {},
   "source": [
    "We are now running Naive Bayes on the scaled training data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7e3531-72f1-49a5-8e95-3a45aab0c05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "Fit = gnb.fit(XTrainS, YTrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8ba23d-0a8e-4790-ab81-dab09fc7d429",
   "metadata": {},
   "source": [
    "In the next step, we want to predict the classes from the test data set using our model and thereby evaluate the quality of the model. Note, that we run *scaler.transform* and not *scaler.fit_transform* on the test set! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a054835-b45c-4696-8d3c-b32af0a3064f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting X and Y from the test data set\n",
    "XTest = Test.drop('label', axis = 1).values\n",
    "YTest = Test['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f2470a-72b5-490c-9841-8a763102f9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling the test set\n",
    "XTestS  = scaler.transform(XTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30828a2f-0187-4096-aaf0-191ea60c1217",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ypred = Fit.predict(XTestS)        #predicting classes\n",
    "Probs = Fit.predict_proba(XTestS)  #calculating probabilities for classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e837230-b43d-4d1a-be8a-e3bad2f4de9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Probs[:30,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decc4827-c444-4e27-84e1-a9a082b1b48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Ypred[:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac600d6-f0cf-4fce-8ba7-b5b537d0e30d",
   "metadata": {},
   "source": [
    "We see that the first column (index = 0) of *Probs* refers to \"Non-Toxic\" and the second column (index = 1) refers to \"Toxic\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d7ce1c-e37f-4089-adcc-70a9b695f133",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33eea5a4-945f-4566-9cbb-a39dfa2eaf83",
   "metadata": {},
   "source": [
    "**4) Model evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37084dd-abdb-4038-bbbb-e4acf6901c16",
   "metadata": {},
   "source": [
    "The most straight forward way in order to evaluate the model is to calculate the accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ace8a07-0f70-43a3-9504-7d096a77d05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = (Ypred == YTest).sum()/len(Ypred)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1edaf5e-d8d9-458d-b34e-9f52358b4f38",
   "metadata": {},
   "source": [
    "But we don't know if there is a bias depending on the class and also how sure the model was when it made it's decission. Therefore, we generate a confusion chart and an entropy plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75e8ea6-aedc-4d4a-8ab8-6b3c4aa44b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "ClassLabs = ['Non-Toxic', 'Toxic']\n",
    "#we have only two classes and label \"Toxic\" to zero and \"Non-Toxic\" to 1\n",
    "Ynum      = [0 if i == 'Non-Toxic' else 1 for i in YTest]\n",
    "YPrednum  = [0 if i == 'Non-Toxic' else 1 for i in Ypred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c7dd10-1256-4b11-a898-63663c61d67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Ynum[:30], YPrednum[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295071ef-8362-42b6-94da-6bd9c8028bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion(YPrednum, Ynum, ClassLabs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901e0fce-2dde-483e-8ded-3fe3b1634dca",
   "metadata": {},
   "source": [
    "That is significantly better than the result we got from logistic regression!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5eb9da-bae9-419c-bf4a-8f2205d8d1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ClassLabsNum = [0, 1]\n",
    "plot_entropy(Probs, Ynum, ClassLabs, ClassLabsNum)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
